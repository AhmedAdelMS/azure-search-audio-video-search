<?xml version="1.0" encoding="utf-8"?>
<tt xml:lang="en-us" xmlns="http://www.w3.org/ns/ttml" xmlns:tts="http://www.w3.org/ns/ttml#styling" xmlns:ttm="http://www.w3.org/ns/ttml#metadata">
  <head>
    <metadata>
      <ttm:title>Media.wvx.aib</ttm:title>
      <ttm:copyright>Copyright (c) 2013 Microsoft Corporation.  All rights reserved.</ttm:copyright>
    </metadata>
    <styling>
      <style xml:id="Style1" tts:fontFamily="proportionalSansSerif" tts:fontSize="0.8c" tts:textAlign="center" tts:color="white" />
    </styling>
    <layout>
      <region style="Style1" xml:id="CaptionArea" tts:origin="0c 12.6c" tts:extent="32c 2.4c" tts:backgroundColor="rgba(0,0,0,160)" tts:displayAlign="center" tts:padding="0.3c 0.5c" />
    </layout>
    <recognizability>0.938</recognizability>
  </head>
  <body region="CaptionArea">
    <div>
      <p begin="00:00:06.140" end="00:00:09.260">Okay.</p>
      <p begin="00:00:09.260" end="00:00:11.140">So,...ready.</p>
      <p begin="00:00:11.140" end="00:00:14.400">Perfect okay everybody hear me okay perfect looks like it's on</p>
      <p begin="00:00:14.400" end="00:00:18.980">now finally great first off thanks-a-lot for coming everybody really appreciate your time</p>
      <p begin="00:00:18.980" end="00:00:24.370">thanks for attending build and talking to us about data for a little while as you saw</p>
      <p begin="00:00:24.370" end="00:00:27.670">in the keynote we've been spending a lot of time talking about data a</p>
      <p begin="00:00:27.670" end="00:00:31.920">lot about a lot of the new data services that have come into asher over the coming</p>
      <p begin="00:00:31.920" end="00:00:36.780">...over the last couple of years and what I wanted to do in this session...spend a little bit of</p>
      <p begin="00:00:36.780" end="00:00:41.750">time talking about how you can compose and use all of those services together to</p>
      <p begin="00:00:41.750" end="00:00:46.230">call to create what we call a data pipeline what we found was that a</p>
      <p begin="00:00:46.230" end="00:00:50.830">lot of solutions people were trying to build to get the most...of their data</p>
      <p begin="00:00:50.830" end="00:00:56.460">follow the typical pattern we call it a pipeline you might here called the data</p>
      <p begin="00:00:56.460" end="00:01:00.940">...integration project etc but what we're going to look at in this talk is</p>
      <p begin="00:01:00.940" end="00:01:04.850">how you can reach out and collect all of the data that's interesting</p>
      <p begin="00:01:04.850" end="00:01:07.870">to you process it transform it analyze it</p>
      <p begin="00:01:07.870" end="00:01:12.820">...predictions based on it and then get it where it needs to be to drive analyst analytics and</p>
      <p begin="00:01:12.820" end="00:01:18.930">by or drive experiences in your app so that whole flow we talk about is creating</p>
      <p begin="00:01:18.930" end="00:01:23.420">a data pipeline...going to do in this session is talk about how you can use all of these new</p>
      <p begin="00:01:23.420" end="00:01:27.040">analytics services and measure combine them together to create this end-to-end</p>
      <p begin="00:01:27.040" end="00:01:30.450">flow but not only get it created get it done in a way</p>
      <p begin="00:01:30.450" end="00:01:34.930">that it sustainable you can monitor it you can manage it if you check in,</p>
      <p begin="00:01:34.930" end="00:01:37.820">you know, an issue you can quickly that debugged...</p>
      <p begin="00:01:37.820" end="00:01:44.990">and move on from there...to spend a lot of time looking at how we go about creating these types of analytics solutions?</p>
      <p begin="00:01:44.990" end="00:01:50.390">Remember submitting email wasn't expecting that either.</p>
      <p begin="00:01:50.390" end="00:01:54.910">In terms of agenda we'll talk a little bit about what and why what I'm from a what perspective</p>
      <p begin="00:01:54.910" end="00:02:00.160">will be what services can...use what is available today...why might you think</p>
      <p begin="00:02:00.160" end="00:02:05.330">about composing these services in different ways what use cases you can target and,</p>
      <p begin="00:02:05.330" end="00:02:08.270">also spend most of the session today talking through</p>
      <p begin="00:02:08.270" end="00:02:13.590">a specific use case that we see build-out in as you're a fair amount</p>
      <p begin="00:02:13.590" end="00:02:17.220">...customer turn analysis it's as simple as</p>
      <p begin="00:02:17.220" end="00:02:21.230">any ppf subscription service any membership etc that you might be providing to your</p>
      <p begin="00:02:21.230" end="00:02:26.230">customers you want to know how much of...how much of that your customers are using do they like it</p>
      <p begin="00:02:26.230" end="00:02:31.120">they not like it are they likely to use less are they likely to cancel their subscription...you</p>
      <p begin="00:02:31.120" end="00:02:36.670">want to analyze all the data available to you to make these informed choices so we'll look at the customer</p>
      <p begin="00:02:36.670" end="00:02:41.000">...analysis example as just kind of an example use across the</p>
      <p begin="00:02:41.000" end="00:02:45.310">talk will actually build-out that pipeline see how it works et cetera?</p>
      <p begin="00:02:45.310" end="00:02:48.900">And, we'll talk about a few other common use cases but the interesting thing is the</p>
      <p begin="00:02:48.900" end="00:02:53.080">patterns that will look at how to bring the services together can be applied to many more use cases</p>
      <p begin="00:02:53.080" end="00:02:59.210">...this will this use this tangible concrete one kind of govern the talk today and,</p>
      <p begin="00:02:59.210" end="00:03:06.580">lastly I'll talk a little bit about road map and, then open it up for questions at the end.</p>
      <p begin="00:03:06.580" end="00:03:12.530">So, with that before working in the data factory services microsoft I spent time</p>
      <p begin="00:03:12.530" end="00:03:17.260">launching...insight service and these were the types of conversations we've been having with</p>
      <p begin="00:03:17.260" end="00:03:22.150">customers over the last two years and it's really been an interesting set of conversations</p>
      <p begin="00:03:22.150" end="00:03:27.150">...people are saying look there's all kinds of data out there either I'm collecting it I'd like to be collecting it</p>
      <p begin="00:03:27.150" end="00:03:31.880">I'd like to be working with it I'm kind of working with it to answer a bunch of different questions whether</p>
      <p begin="00:03:31.880" end="00:03:36.590">there traditional by questions over more data or different sources of data all the way through</p>
      <p begin="00:03:36.590" end="00:03:39.840">to predictive questions where I'm trying to use data pretty predict what's going to</p>
      <p begin="00:03:39.840" end="00:03:44.670">happen in the future as I mentioned will focus on the kind of predictive customer</p>
      <p begin="00:03:44.670" end="00:03:50.370">...scenario...touch on a few more throughout the talk as well what we're really going to dive</p>
      <p begin="00:03:50.370" end="00:03:54.900">into the customer...scenarios you can see the pieces and parts how to go about building and</p>
      <p begin="00:03:54.900" end="00:04:00.020">analytics pipeline on as your composing all of the various services together.</p>
      <p begin="00:04:00.020" end="00:04:04.160">So, with that that's going to jump into the media the talk and a</p>
      <p begin="00:04:04.160" end="00:04:06.770">...a question we get...a lot is you guys</p>
      <p begin="00:04:06.770" end="00:04:11.270">launched this service called as your data factory why the heck did you call it data factory what...trying to do with</p>
      <p begin="00:04:11.270" end="00:04:15.020">this service and the reason for that was that a lot of the</p>
      <p begin="00:04:15.020" end="00:04:18.010">analytics solutions we saw people building really</p>
      <p begin="00:04:18.010" end="00:04:23.400">follow the typical flow that you'd see in an assembly line in a manufacturing plant</p>
      <p begin="00:04:23.400" end="00:04:28.570">which is you have to collect all of the raw materials you think you may need to your loading dock</p>
      <p begin="00:04:28.570" end="00:04:32.830">you're then going to assemble or create an assembly line that assembly lines</p>
      <p begin="00:04:32.830" end="00:04:37.590">going-to work on those raw materials it's going to have all kinds of fit for purpose machines they</p>
      <p begin="00:04:37.590" end="00:04:41.660">work on that material transform that material combine it and finally you've got some type of</p>
      <p begin="00:04:41.660" end="00:04:44.140">...good and then lastly you want to deliver that</p>
      <p begin="00:04:44.140" end="00:04:48.500">...good ...your consumer...somebody somebody's</p>
      <p begin="00:04:48.500" end="00:04:53.800">...good might be another person's raw material and the process repeats itself so you end up with a</p>
      <p begin="00:04:53.800" end="00:04:57.790">is...manufacturing perspective a pipeline it looks something like this if we were</p>
      <p begin="00:04:57.790" end="00:05:01.450">to overlay more data words on top of this.</p>
      <p begin="00:05:01.450" end="00:05:03.260">We talk about our data sources</p>
      <p begin="00:05:03.260" end="00:05:06.930">are raw materials we need to ingesting collect those data those</p>
      <p begin="00:05:06.930" end="00:05:11.720">date that data from those data sources whether they be on prim data coming from sas apps</p>
      <p begin="00:05:11.720" end="00:05:16.490">data coming from the cloud whether it's a relational database ahead dupes source of file share</p>
      <p begin="00:05:16.490" end="00:05:21.080">etc all of that data we want to be able to work with an address for analytics</p>
      <p begin="00:05:21.080" end="00:05:26.070">purposes we think about ingesting all of that data...and analyze regardless of</p>
      <p begin="00:05:26.070" end="00:05:30.320">shape speed etc we want to be able to work with munged that data</p>
      <p begin="00:05:30.320" end="00:05:34.080">from analysis perspective we might do that simple things like trying</p>
      <p begin="00:05:34.080" end="00:05:39.010">to aggregate and report on data all the way through tomore predictive things</p>
      <p begin="00:05:39.010" end="00:05:43.970">like using data to predict particular outcomes and then lastly you want to able to publisher</p>
      <p begin="00:05:43.970" end="00:05:48.900">data in this particular case or in the sense of this talk publish means taking</p>
      <p begin="00:05:48.900" end="00:05:53.860">that finished good that you've produced from your data pipeline and getting it to where it needs to be for</p>
      <p begin="00:05:53.860" end="00:05:58.990">most efficient consumption what I mean by that is you might be processing data with a do</p>
      <p begin="00:05:58.990" end="00:06:03.730">you want to get it to a relational database or the or data warehouse back on prime to</p>
      <p begin="00:06:03.730" end="00:06:08.730">connect your existing by infrastructure it could mean...no sequel store</p>
      <p begin="00:06:08.730" end="00:06:13.700">or search index with some interesting data that's been generated by your pipelines that applications can</p>
      <p begin="00:06:13.700" end="00:06:18.060">consume it we see all kinds of interesting scenarios for these analytics pipelines</p>
      <p begin="00:06:18.060" end="00:06:23.690">...ingesting transforming data and loading it into places for all kinds of interesting consumption</p>
      <p begin="00:06:23.690" end="00:06:30.140">so if we look at the this predicting customer turn scenario and a little more detail I</p>
      <p begin="00:06:30.140" end="00:06:35.570">...to data sources that will use as are raw materials for the talk one</p>
      <p begin="00:06:35.570" end="00:06:40.560">is a bunch of log files the other one is more structured data and what we'll do is</p>
      <p begin="00:06:40.560" end="00:06:45.780">will build-out analytics pipeline that nears what you might do if you were like</p>
      <p begin="00:06:45.780" end="00:06:49.690">a telescope or a mobile phone carrier where you've got</p>
      <p begin="00:06:49.690" end="00:06:53.570">...people subscribe to your service everybody's got a phone in their pocket so I figured this</p>
      <p begin="00:06:53.570" end="00:06:59.090">would be a good one that everyone can relate to but again the pattern applies very broadly so,</p>
      <p begin="00:06:59.090" end="00:07:04.690">our scenario will be you've got a telescope from a very-high-level the way it works is,</p>
      <p begin="00:07:04.690" end="00:07:09.560">you know, we're...making...phone calls that's being routed...kinds of infrastructure that</p>
      <p begin="00:07:09.560" end="00:07:14.040">infrastructures actually logging everything about our phone calls from the numbers</p>
      <p begin="00:07:14.040" end="00:07:19.310">that we call from the very sim cards due to the length of our calls to the drop of the</p>
      <p begin="00:07:19.310" end="00:07:23.020">call through the quality of the call through to the...that</p>
      <p begin="00:07:23.020" end="00:07:27.900">the particular call took to connect me to you etc all of that data is being...what if we could</p>
      <p begin="00:07:27.900" end="00:07:33.590">...that data to extract insight from it so the first raw material for a pipeline is the</p>
      <p begin="00:07:33.590" end="00:07:38.120">actual log files coming off the cell infrastructure the second raw material that will use for a</p>
      <p begin="00:07:38.120" end="00:07:43.410">pipeline is more structured information every business has data warehouses today</p>
      <p begin="00:07:43.410" end="00:07:45.840">right you seen all of our announcements but whereas every business</p>
      <p begin="00:07:45.840" end="00:07:51.270">has warehouses where you keep that structured information in this particular case for mythical</p>
      <p begin="00:07:51.270" end="00:07:58.110">telescope we're we've got a customer list of your authoritative customer list...very likely</p>
      <p begin="00:07:58.110" end="00:08:02.850">...on prime warehouse somewhere that lists who your customers are</p>
      <p begin="00:08:02.850" end="00:08:06.480">when did they sign up how old they are all the typical stuff you have when, you know,</p>
      <p begin="00:08:06.480" end="00:08:10.450">customer signs up your service at the end of the day with the tokyo's trying</p>
      <p begin="00:08:10.450" end="00:08:15.260">to do is come up with a finish good that looks more like this and being a</p>
      <p begin="00:08:15.260" end="00:08:21.110">data geek I consider this a finished good another data set not being a data geek that's probably</p>
      <p begin="00:08:21.110" end="00:08:26.130">finish good but the idea here is to create a pipeline that can ingest that data</p>
      <p begin="00:08:26.130" end="00:08:31.530">transform that data predict based on that usage data and tell you</p>
      <p begin="00:08:31.530" end="00:08:35.960">which customers which of your customers are more or less likely to churn where</p>
      <p begin="00:08:35.960" end="00:08:40.500">churn here is defined as use less of your service or product or cancel your subscription</p>
      <p begin="00:08:40.500" end="00:08:45.320">with your service or product so we want to be able to do is ingest that data transform that data run</p>
      <p begin="00:08:45.320" end="00:08:49.870">machining learning on that data to come up with this finished good and then do it repeatedly</p>
      <p begin="00:08:49.870" end="00:08:54.360">right because every month role making calls well making decisions and how we feel about,</p>
      <p begin="00:08:54.360" end="00:08:58.160">you know, our cellphone coverage and everything like that so what we'll do is</p>
      <p begin="00:08:58.160" end="00:09:02.220">will create a pipeline that's running all the time and the pipeline is</p>
      <p begin="00:09:02.220" end="00:09:07.750">going-to be working over a month's worth of data at a time so we're going...create a time-based</p>
      <p begin="00:09:07.750" end="00:09:11.510">...where every month will be ingesting this</p>
      <p begin="00:09:11.510" end="00:09:17.070">input data every month will be analyzing and transforming that data to come up with</p>
      <p begin="00:09:17.070" end="00:09:21.500">this data set which is effectively the customers likely to cer next month?</p>
      <p begin="00:09:21.500" end="00:09:23.600">Okay, and,</p>
      <p begin="00:09:23.600" end="00:09:28.410">again,...I consider this a...good but more than likely the actual</p>
      <p begin="00:09:28.410" end="00:09:33.030">...good in something like this will be a report that your marketing team your custer engagement team may want to</p>
      <p begin="00:09:33.030" end="00:09:37.910">pick up and say okay these are the people likely to churn I may want to target them with special offers</p>
      <p begin="00:09:37.910" end="00:09:42.870">...I want to reach out to them and get ahead of customers before they start canceling</p>
      <p begin="00:09:42.870" end="00:09:49.320">...reducing usage points the interesting thing is this pattern is actually something we've</p>
      <p begin="00:09:49.320" end="00:09:54.310">extracted from a set of our customers in production today with data factory in hd inside</p>
      <p begin="00:09:54.310" end="00:09:58.330">and blob store we just generalized it for the...something that</p>
      <p begin="00:09:58.330" end="00:10:04.490">we've got a fair amount of experience with I've just kind of...it to the delco...I thought everybody could relate?</p>
      <p begin="00:10:04.490" end="00:10:09.030">So, with that given this is build that's going to dig in and see how pipeline like this can</p>
      <p begin="00:10:09.030" end="00:10:13.980">be built using the services that are available and...today.</p>
      <p begin="00:10:13.980" end="00:10:20.230">So, first step we need some raw data that's supposed to be a</p>
      <p begin="00:10:20.230" end="00:10:25.720">cellphone tower I apologize for my for art but the raw data here</p>
      <p begin="00:10:25.720" end="00:10:30.450">is cellphone towers all over the place that are collecting these log files typically these files are</p>
      <p begin="00:10:30.450" end="00:10:34.820">called cdr files called detail records they get pushed to all kinds of</p>
      <p begin="00:10:34.820" end="00:10:37.500">file store infrastructure whether that's, you know,</p>
      <p begin="00:10:37.500" end="00:10:40.340">file stores in on prime situation ftp servers</p>
      <p begin="00:10:40.340" end="00:10:46.250">et cetera but they get log then we've got a customer table in on prim data mart data warehouse</p>
      <p begin="00:10:46.250" end="00:10:50.710">et cetera and what we want to be able to do is collect all of that data?</p>
      <p begin="00:10:50.710" end="00:10:55.680">we want to put it into a place that we can run analysis on it at scale regardless of the shape</p>
      <p begin="00:10:55.680" end="00:11:00.790">size or etc of the data so a great way to do that today is to use as your</p>
      <p begin="00:11:00.790" end="00:11:03.160">blob storage just ingest all of the data into</p>
      <p begin="00:11:03.160" end="00:11:07.720">...blob storage built into as your data factory is a globally available data</p>
      <p begin="00:11:07.720" end="00:11:12.600">movement service that knows how to reach backed on prim sources...get data knows how to reach the file</p>
      <p begin="00:11:12.600" end="00:11:16.920">source of file shares and get datamove data among blob stores</p>
      <p begin="00:11:16.920" end="00:11:21.910">so ingesting data can be facilitated by the globally available movement service in data factory</p>
      <p begin="00:11:22.940" end="00:11:27.690">you push that data into blob storage if anybody's not familiar with as your blob storage</p>
      <p begin="00:11:27.690" end="00:11:33.510">its effectively file store in the cloud you can put anything in it it's scale out.</p>
      <p begin="00:11:33.510" end="00:11:38.540">Highly available and its dirt-cheap so you start to be able to take this methodology or mentality</p>
      <p begin="00:11:38.540" end="00:11:43.420">of collect everything is kind of the loading dock if you will of your pipeline or your assembly</p>
      <p begin="00:11:43.420" end="00:11:48.660">line collect everything into blob storage you may have a scenario for that data</p>
      <p begin="00:11:48.660" end="00:11:53.440">out of the gate you may learn about a new scenario for that data down the line collect everything it's</p>
      <p begin="00:11:53.440" end="00:11:58.870">now kind of economically possible to go do that it's really cheap to put things in blob storage once</p>
      <p begin="00:11:58.870" end="00:12:03.810">you've collected stuff your next step is to actually create just like a manufacturing plant create your</p>
      <p begin="00:12:03.810" end="00:12:08.750">assembly line what's going to work on this data and this is where it's pretty fun to be</p>
      <p begin="00:12:08.750" end="00:12:13.810">in data right now obviously...data so I say that but it's really fun time because there's</p>
      <p begin="00:12:13.810" end="00:12:19.240">a lot more tools that we have available then we used to so now it's not just</p>
      <p begin="00:12:19.240" end="00:12:24.170">okay can I represent that data in sql but I can have a bunch of tools that are fit for</p>
      <p begin="00:12:24.170" end="00:12:29.050">purpose depending upon what I want to and with data factory what we can do is compose all of</p>
      <p begin="00:12:29.050" end="00:12:34.120">those fit for purpose tools to work on the data as...as we need so the first thing we're going</p>
      <p begin="00:12:34.120" end="00:12:38.770">to go do is create a pipeline and that pipeline is going to start by using</p>
      <p begin="00:12:38.770" end="00:12:44.080">simply do processing to process these very large collection of</p>
      <p begin="00:12:44.080" end="00:12:48.860">log files if you think about it think of every call anybody's making in the united states for</p>
      <p begin="00:12:48.860" end="00:12:53.640">a particular carrier being able to ingest all of that data and process it monthly</p>
      <p begin="00:12:53.640" end="00:12:58.390">...up with row one row that says might flask go talk to this many minutes...this many drop</p>
      <p begin="00:12:58.390" end="00:13:04.350">calls here this many calls, you know, internationally domestically et cetera that's what</p>
      <p begin="00:13:04.350" end="00:13:08.290">dupe is going to do for us in this particular stage or first stage to</p>
      <p begin="00:13:08.290" end="00:13:13.070">kind of transforming combine the data is going to aggregate all of those call logs to generate</p>
      <p begin="00:13:13.070" end="00:13:17.610">literally one record per customer per month it's going to combine that data with the</p>
      <p begin="00:13:17.610" end="00:13:21.380">on prim reference data which is our customer list so it's not just</p>
      <p begin="00:13:21.380" end="00:13:25.490">...card...long but it's mike flask go of age,</p>
      <p begin="00:13:25.490" end="00:13:30.830">you know, what I know what I put myself in here thirty two talk to this long</p>
      <p begin="00:13:30.830" end="00:13:35.540">...this many drop calls...so now you can get a very personal sense of exactly what</p>
      <p begin="00:13:35.540" end="00:13:41.360">you're customers have been doing in the experience they've had with your service once we've got that data kind...we</p>
      <p begin="00:13:41.360" end="00:13:46.480">...we transformed it with hd insight the next step will be to take that</p>
      <p begin="00:13:46.480" end="00:13:50.140">output data which I've called here the customer called details?</p>
      <p begin="00:13:51.300" end="00:13:54.650">And, push that output data into an as your</p>
      <p begin="00:13:54.650" end="00:13:58.800">machine learning model and we're going to use a machine learning model that's available in the</p>
      <p begin="00:13:58.800" end="00:14:03.320">machine learning gallery what it's going to do is take that data as input one</p>
      <p begin="00:14:03.320" end="00:14:08.010">role per each customer and it's going to look at all that data and compare</p>
      <p begin="00:14:08.010" end="00:14:12.910">it to training data we've used for customers who have cancel their subscriptions in the past and it's going</p>
      <p begin="00:14:12.910" end="00:14:18.430">to predict which customers are likely to churn basically which customers are</p>
      <p begin="00:14:18.430" end="00:14:23.380">more or less likely to cancel their subscription or use less from this particular</p>
      <p begin="00:14:23.380" end="00:14:27.880">telescope and then...that's going to output...data set called customers likely to</p>
      <p begin="00:14:27.880" end="00:14:32.670">churn lastly you may want to move that datasets you may want to take it out a blob</p>
      <p begin="00:14:32.670" end="00:14:37.540">...push back on prim to your data warehouse for reporting you may want to take that data set push it</p>
      <p begin="00:14:37.540" end="00:14:41.360">too, you know, another store for sharing with a partner whatever the</p>
      <p begin="00:14:41.360" end="00:14:46.660">...consumption pattern is for this particular piece of data in this case we're going to do is move the</p>
      <p begin="00:14:46.660" end="00:14:51.440">data to cloud database and measure db going forward the as your</p>
      <p begin="00:14:51.440" end="00:14:54.000">data warehouse service will be a great option it will</p>
      <p begin="00:14:54.000" end="00:14:58.420">be natively supported by data factory and then lastly what-you want-to do is</p>
      <p begin="00:14:58.420" end="00:15:01.850">create a visualization right for me the table and</p>
      <p begin="00:15:01.850" end="00:15:06.720">...is...good for me but foryour marketing team</p>
      <p begin="00:15:06.720" end="00:15:12.960">...customer engagement team they're probably want to report so...here would be some type of report you've,</p>
      <p begin="00:15:12.960" end="00:15:17.070">you've created over top of that data so effectively this is what we want to have</p>
      <p begin="00:15:17.070" end="00:15:22.010">happen we want to work with the actual log files from how people were interacting with their</p>
      <p begin="00:15:22.010" end="00:15:26.060">phones and transform that into report about a...uri</p>
      <p begin="00:15:26.060" end="00:15:30.270">more or less likely to churn based on the experience we've had with the service and we want that to</p>
      <p begin="00:15:30.270" end="00:15:36.870">...every month and we want to unreliable every month and we want it to be able to improve it</p>
      <p begin="00:15:36.870" end="00:15:40.640">...increment on it every month so we want to be able to run this whole thing</p>
      <p begin="00:15:40.640" end="00:15:47.110">is a single pipeline operated as a single...highly available.</p>
      <p begin="00:15:47.110" end="00:15:49.300">I've been using the were data factory...throat</p>
      <p begin="00:15:49.300" end="00:15:53.910">the my description data factory is a purdue preview service we have and measure that</p>
      <p begin="00:15:53.910" end="00:15:58.780">effectively lets you model this entire data flow as what we call a pipeline</p>
      <p begin="00:15:58.780" end="00:16:03.520">in data factory so I'm going to introduce you to three key concepts that's in the data</p>
      <p begin="00:16:03.520" end="00:16:08.450">factory service that allows you to compose these as your services together into these types of</p>
      <p begin="00:16:08.450" end="00:16:14.590">data flows are pipelines the first key concept in data factories called the data set a data set</p>
      <p begin="00:16:14.590" end="00:16:19.200">is just that it's a piece of data you want to work with in your analytics pipeline a</p>
      <p begin="00:16:19.200" end="00:16:23.240">data set could represent a table in a database a piece of structured data a</p>
      <p begin="00:16:23.240" end="00:16:27.580">data set represent a bunch of log files that you have</p>
      <p begin="00:16:27.580" end="00:16:32.540">in blob storage that you want to treated as a single data set it really can represent any piece of data</p>
      <p begin="00:16:32.540" end="00:16:36.150">...a...data set is just a piece of metadata in data factory</p>
      <p begin="00:16:36.150" end="00:16:42.100">in assertion about a piece of data at a particular location next key concept...data factories called</p>
      <p begin="00:16:42.100" end="00:16:47.060">an activity and activity is a processing job it's something that works on the</p>
      <p begin="00:16:47.060" end="00:16:51.980">data either moves data transforms data shapes data doesn't prediction</p>
      <p begin="00:16:51.980" end="00:16:56.800">on data so in our in our scenario today the activities in our</p>
      <p begin="00:16:56.800" end="00:16:59.720">pipelined will be simple dupe activities some</p>
      <p begin="00:16:59.720" end="00:17:04.930">high even pig work followed by the execution of a machine learning model and</p>
      <p begin="00:17:04.930" end="00:17:09.320">measure ml model that's also considered activity and then lastly will move</p>
      <p begin="00:17:09.320" end="00:17:14.940">the data to as your db and that movement step is also considered</p>
      <p begin="00:17:14.940" end="00:17:19.680">an activity in the data factory and the interesting thing again is that</p>
      <p begin="00:17:19.680" end="00:17:25.060">activities are just assertions of work that is going to happen on particular services</p>
      <p begin="00:17:25.060" end="00:17:27.580">the data factory does the job of</p>
      <p begin="00:17:27.580" end="00:17:34.280">orchestrating the work among the services the scheduling the monitoring actually making the pipeline flow.</p>
      <p begin="00:17:34.280" end="00:17:38.590">And, lastly you can organize your activities</p>
      <p begin="00:17:38.590" end="00:17:42.920">into kind of logical sequences we call those things pipelines</p>
      <p begin="00:17:42.920" end="00:17:47.740">...pipeline is just and ordered set of activities it's a logical grouping you think about how you</p>
      <p begin="00:17:47.740" end="00:17:52.170">organize a set of classes into a dl or methods into a class it's the same kind of</p>
      <p begin="00:17:52.170" end="00:17:56.010">thing data factor you organize a set of steps into you know,</p>
      <p begin="00:17:56.010" end="00:18:00.710">whatever granularity you want you could have a pipelined of thirty steps you have a pipeline of</p>
      <p begin="00:18:00.710" end="00:18:06.250">one-step-at-a-time...up to you it's...organizational tool for you to say, you know, what this eighteen</p>
      <p begin="00:18:06.250" end="00:18:11.070">site job followed by this machine learning model invocation followed by this move this particular set of steps</p>
      <p begin="00:18:11.070" end="00:18:15.980">this-is mike calculate customer turn pipeline and that allows me just kind of reason about the things a</p>
      <p begin="00:18:15.980" end="00:18:18.610">little more organized way?</p>
      <p begin="00:18:18.610" end="00:18:21.120">So, with that I think back to the analogy to</p>
      <p begin="00:18:21.120" end="00:18:25.650">the factory floor to the assembly line these are the core steps that you see in a lot of</p>
      <p begin="00:18:25.650" end="00:18:29.140">these solutions collect the data from the data sources that you need</p>
      <p begin="00:18:29.140" end="00:18:33.230">...connect to them ingest them transform and analyze publish the data</p>
      <p begin="00:18:33.230" end="00:18:38.450">...hear me reference that the structure of fairmount throughout the talk today so with</p>
      <p begin="00:18:38.450" end="00:18:41.230">that I hopefully I've set the stage on what</p>
      <p begin="00:18:41.230" end="00:18:45.620">we're trying to do how the various as your services will be used and what role</p>
      <p begin="00:18:45.620" end="00:18:49.810">that play-along are pipeline and now what I'll do is I'll jump out of</p>
      <p begin="00:18:49.810" end="00:18:54.370">slides and get into the as your portal and show you this solution actually running</p>
      <p begin="00:18:54.370" end="00:18:59.850">and as your today and we'll walk...step-by-step and see how it's built?</p>
      <p begin="00:18:59.850" end="00:19:05.620">...so let me flip over here.</p>
      <p begin="00:19:05.620" end="00:19:08.360">The real great okay.</p>
      <p begin="00:19:08.360" end="00:19:09.630">So, we'll start in the as</p>
      <p begin="00:19:09.630" end="00:19:14.460">your portal and if you want to build one of these analytics pipelines the way to start</p>
      <p begin="00:19:14.460" end="00:19:18.640">is by instantiating a data factory data factory think of it just like,</p>
      <p begin="00:19:18.640" end="00:19:23.640">you know, that the manufacturing plant when you create a new data factor it's like having</p>
      <p begin="00:19:23.640" end="00:19:28.700">an empty manufacturing plant there's no assembly lines anywhere it's just like an empty building</p>
      <p begin="00:19:28.700" end="00:19:33.610">so when I go and say I want to create a new data factory your effectively</p>
      <p begin="00:19:33.610" end="00:19:38.640">trading the start of your manufacturing plant a new data factory is</p>
      <p begin="00:19:38.640" end="00:19:43.650">...using any resources it's free to create data factories until you start putting pipelines into</p>
      <p begin="00:19:43.650" end="00:19:49.860">them creating a data factory takes a few seconds it's just a metadata operation.</p>
      <p begin="00:19:49.860" end="00:19:54.580">So, I'm not going to create a new one but instead what I'm going to go do is open one that I've already created that</p>
      <p begin="00:19:54.580" end="00:19:58.720">has the solution running and will look at it so here I've got my</p>
      <p begin="00:19:58.720" end="00:20:04.110">the customer turn the data factory loading up?</p>
      <p begin="00:20:04.110" end="00:20:08.830">On the home blade of data factory you get kind of an added glance view of what's in the</p>
      <p begin="00:20:08.830" end="00:20:13.810">factory we just talked about what datasets are those are all the concrete pieces of data will work</p>
      <p begin="00:20:13.810" end="00:20:18.600">with pipelines again or just sequences of activities the one thing I</p>
      <p begin="00:20:18.600" end="00:20:22.580">didn't mention was linked services links services are very simple</p>
      <p begin="00:20:22.580" end="00:20:26.220">...just the other as your services or other services that</p>
      <p begin="00:20:26.220" end="00:20:31.110">we've link to the data factory that it can...they can communicate with so if I look</p>
      <p begin="00:20:31.110" end="00:20:36.500">at this you can see what I've got here is I've link to the factory a couple of</p>
      <p begin="00:20:36.500" end="00:20:40.180">storage...storage accounts and as your db in as</p>
      <p begin="00:20:40.180" end="00:20:44.330">...machine learning account and then finally a cluster.</p>
      <p begin="00:20:45.430" end="00:20:49.130">And, this is just all of the services that are being composed into my pipelined</p>
      <p begin="00:20:49.130" end="00:20:54.100">by the factory if I wanted to work with some more data maybe I want to work with an oracle database on</p>
      <p begin="00:20:54.100" end="00:20:58.010">prim I can go and add my links service that oracle database maybe</p>
      <p begin="00:20:58.010" end="00:21:01.420">non-credit file share etc so through here I can start to</p>
      <p begin="00:21:01.420" end="00:21:05.440">...more what you'll see is more in-box connectors to various data sources</p>
      <p begin="00:21:05.440" end="00:21:10.830">at each month as we go and there's support in data factory as I mentioned before for</p>
      <p begin="00:21:10.830" end="00:21:16.320">moving data connecting to data sources whether they be on primer cloud the on prime connectivity</p>
      <p begin="00:21:16.320" end="00:21:18.360">...facilitated through something we call</p>
      <p begin="00:21:18.360" end="00:21:22.810">the data management gateway you can set up those gateways right through the cloud portal</p>
      <p begin="00:21:22.810" end="00:21:29.440">as well it gives you a piece of software to install on your side of the firewall and it helps manage communication.</p>
      <p begin="00:21:29.440" end="00:21:32.130">So, let me rollback so now I've got a data factory it's</p>
      <p begin="00:21:32.130" end="00:21:38.150">...to some hd insight clusters and storage accounts sequel db</p>
      <p begin="00:21:38.150" end="00:21:42.850">And, about...pipelines created the best way to work with the data factory if you're coming into one</p>
      <p begin="00:21:42.850" end="00:21:47.150">brand-new I often suggest people to go and click sample pipelines</p>
      <p begin="00:21:47.150" end="00:21:51.840">what this will do is deploy one of our end-to-end samples right into your factories so it</p>
      <p begin="00:21:51.840" end="00:21:56.800">can be up and running and you can see how everything works it's a great way to get started but in this case because</p>
      <p begin="00:21:56.800" end="00:22:02.910">I've already deployed this customer turns scenario I'm going to start with the diagram</p>
      <p begin="00:22:02.910" end="00:22:07.400">view diagram view gives me a complete look at everything that's deployed</p>
      <p begin="00:22:07.400" end="00:22:11.460">in the factory it's an infinite canvas kind of thing so that you can have</p>
      <p begin="00:22:11.460" end="00:22:15.540">is many pipelines as you want in a single factories many datasets as you</p>
      <p begin="00:22:15.540" end="00:22:19.520">author scale limits from that perspective and the idea is that the diagram</p>
      <p begin="00:22:19.520" end="00:22:24.150">view shows you exactly what's deployed and what's healthy and running in terms of pipelines</p>
      <p begin="00:22:24.150" end="00:22:28.920">in your factory and what I'm going to do now is kind of take you from left to right on this</p>
      <p begin="00:22:28.920" end="00:22:35.560">pipeline and show you how it's built this is mimicking what we just looked at in slide's okay?</p>
      <p begin="00:22:35.560" end="00:22:46.000">So, let me zoom in and walk it step-by-step and show you how this is built.</p>
      <p begin="00:22:46.000" end="00:22:50.320">The enough fifth-grade okay that's cool what bigger.</p>
      <p begin="00:22:50.320" end="00:22:56.280">All right so on the far-left we're not actually collecting data live from cellphone towers</p>
      <p begin="00:22:56.280" end="00:23:00.660">as I mentioned we could hook up alive ingestion from file shares if we wanted</p>
      <p begin="00:23:00.660" end="00:23:04.540">there's extensibility points to be able to connect other stores...we've done is we've</p>
      <p begin="00:23:04.540" end="00:23:08.830">just added something on the far-left that is mimicking the generation of</p>
      <p begin="00:23:08.830" end="00:23:13.820">...cellphone log files are called detail records this is actually live in a piece of python code running on</p>
      <p begin="00:23:13.820" end="00:23:19.780">how to cluster so just for fun we use python running on...to generate the data but...typical pipeline</p>
      <p begin="00:23:19.780" end="00:23:24.570">would start right here and it would start with that log data a single</p>
      <p begin="00:23:24.570" end="00:23:28.940">datasets representing all of the log files for particular month</p>
      <p begin="00:23:28.940" end="00:23:35.000">from my delco so maybe all the log files from january...fails from february</p>
      <p begin="00:23:36.290" end="00:23:39.780">The way you do this is you basically</p>
      <p begin="00:23:39.780" end="00:23:44.780">specified just adjacent document adjacent document tells us where the data is</p>
      <p begin="00:23:44.780" end="00:23:50.160">what it structure might be where it's located so what this data actually looks</p>
      <p begin="00:23:50.160" end="00:23:55.260">like in blob store it looks like this is kind of a typical called detail record just a</p>
      <p begin="00:23:55.260" end="00:24:00.770">bunch of semi-structured log files about who called what where how long etc.</p>
      <p begin="00:24:00.770" end="00:24:03.930">And, the...describe that in terms of a pipeline</p>
      <p begin="00:24:03.930" end="00:24:07.180">...a factories to my data set if I double-click</p>
      <p begin="00:24:07.180" end="00:24:13.050">the data set it's going to give me kind of a live view of how healthy that data set is has</p>
      <p begin="00:24:13.050" end="00:24:17.860">been generated etc I can look at the source for the particular data...so we have a</p>
      <p begin="00:24:17.860" end="00:24:22.730">and editor built into the portal as well so you can look at the definition of a data set</p>
      <p begin="00:24:22.730" end="00:24:26.400">and you can edit you can deploy new ones et cetera</p>
      <p begin="00:24:26.400" end="00:24:34.840">but I've copied one out just a...inspecting little more detail.</p>
      <p begin="00:24:34.840" end="00:24:38.900">But, what I'm going to do apps...forgot what I'm going to do is I'm actually going to look at the data</p>
      <p begin="00:24:38.900" end="00:24:43.860">set over here so what's happening in between this piece of data and this piece of data is</p>
      <p begin="00:24:43.860" end="00:24:48.540">one step that is just partitioning the incoming data so if you think of these log files</p>
      <p begin="00:24:48.540" end="00:24:53.030">is coming in all the time being landed in maybe one container and blob store</p>
      <p begin="00:24:53.030" end="00:24:57.600">this one step in this pipeline is just taking the data out of that container taking all</p>
      <p begin="00:24:57.600" end="00:25:01.480">the logs for january putting in a january folder taking...the...february putting</p>
      <p begin="00:25:01.480" end="00:25:06.350">...february folder and its accomplishing that task at scale by running a</p>
      <p begin="00:25:06.350" end="00:25:12.370">hype script on hd insight cluster so if I go down here you can see the activity is</p>
      <p begin="00:25:12.370" end="00:25:16.980">actually a piece of five code it's running on hd insight cluster that's happening at scale</p>
      <p begin="00:25:16.980" end="00:25:20.950">all dig into one of the subsequent hype scripts in a little more detail so I'll just kind of</p>
      <p begin="00:25:20.950" end="00:25:24.510">...over this one for now so at the end of it what</p>
      <p begin="00:25:24.510" end="00:25:29.370">we've got is data that came in one container we partitioned it so it's ready for kind</p>
      <p begin="00:25:29.370" end="00:25:34.480">of longer-term storage and then what I'm going to do is I'm going to dig into this pipeline in these data sets a little more</p>
      <p begin="00:25:34.480" end="00:25:37.780">detail...you can see so partition cdr data</p>
      <p begin="00:25:37.780" end="00:25:42.580">...in blob storage let's look at how you create an actual data set?</p>
      <p begin="00:25:42.580" end="00:25:44.190">Here's the definition of that</p>
      <p begin="00:25:44.190" end="00:25:48.990">...set it's just a simple jason document you can do this programmatic</p>
      <p begin="00:25:48.990" end="00:25:53.080">lee you can do it through the ui like I showed but I wanted to show you is kind of under the covers</p>
      <p begin="00:25:53.080" end="00:25:58.160">possible these things are so to create a data set and added to data factory you create a simple jason</p>
      <p begin="00:25:58.160" end="00:26:04.010">object you name it and it's got three sections structure location availability,</p>
      <p begin="00:26:04.010" end="00:26:08.640">availability is just saying kind of what the frequency is that this data set is being</p>
      <p begin="00:26:08.640" end="00:26:12.930">attended to or updated so you can think of this...time slicing of the data set</p>
      <p begin="00:26:12.930" end="00:26:17.770">so if you imagine that these log files is one big long data set where basically</p>
      <p begin="00:26:17.770" end="00:26:23.870">saying it's sliced monthly so there's the january partition the february partition etc.</p>
      <p begin="00:26:23.870" end="00:26:26.950">We're asserting some structure about this data set</p>
      <p begin="00:26:26.950" end="00:26:30.530">just like in who do you've got a bunch of log file sitting in blob store and</p>
      <p begin="00:26:30.530" end="00:26:34.790">see effectively asserting structure about or schema about what's in that blobs</p>
      <p begin="00:26:34.790" end="00:26:39.490">...what's in those log files and I've actually shorten this just for the</p>
      <p begin="00:26:39.490" end="00:26:44.020">...demo but the idea is that here's the first column and its type here's the second</p>
      <p begin="00:26:44.020" end="00:26:48.500">column and I removed all the other columns just so I don't scroll through the thirty call my</p>
      <p begin="00:26:48.500" end="00:26:52.950">thinker so wide us the schema definition</p>
      <p begin="00:26:52.950" end="00:26:57.210">...lastly this is the kind of meat of the data set definition is location</p>
      <p begin="00:26:57.210" end="00:27:01.150">so data set is just a pointer to a piece of data you saying this data is</p>
      <p begin="00:27:01.150" end="00:27:05.910">in blobs this data is partition by year and month.</p>
      <p begin="00:27:05.910" end="00:27:08.440">...a variable here it's a</p>
      <p begin="00:27:08.440" end="00:27:15.980">common limited file and here's the partitioning scheme and what we're saying is?</p>
      <p begin="00:27:15.980" end="00:27:19.800">This data is partition by your and month and we're using one of the environment</p>
      <p begin="00:27:19.800" end="00:27:25.390">variables we injected into the system called slice start there's also one called slice so,</p>
      <p begin="00:27:25.390" end="00:27:29.570">if you remember I said this particular data set is sliced by time what we mean by</p>
      <p begin="00:27:29.570" end="00:27:33.490">sliced by time is each time there's an activity that runs to</p>
      <p begin="00:27:33.490" end="00:27:38.720">produce this data that activities going to run monthly in this case so slice start would</p>
      <p begin="00:27:38.720" end="00:27:44.120">represent like january first-year slice and represent like january thirtieth so what's happening is</p>
      <p begin="00:27:44.120" end="00:27:49.890">you're just defining the data set and how...partitioned lastly?</p>
      <p begin="00:27:49.890" end="00:27:54.840">We're saying this data set well stored in blob store is stored in this particular</p>
      <p begin="00:27:54.840" end="00:27:59.230">...service so what we do is we have a generic definition about the data and where</p>
      <p begin="00:27:59.230" end="00:28:04.230">...stored in a particular kind in this case a blob storage and then this last</p>
      <p begin="00:28:04.230" end="00:28:08.030">binding to assist to a link service is basically binding it to a particular</p>
      <p begin="00:28:08.030" end="00:28:12.820">blob storage account so at this point all I've done is describe the data that's going to be used by</p>
      <p begin="00:28:12.820" end="00:28:15.960">...subsequent step in the pipeline?</p>
      <p begin="00:28:15.960" end="00:28:20.430">So, if I go back I've got this step that's taking that data set is input it's also</p>
      <p begin="00:28:20.430" end="00:28:25.320">taking another data set called mobile customers as input this data just for the sake of</p>
      <p begin="00:28:25.320" end="00:28:29.930">the demo I...staged into blob store but I could be connecting this up to</p>
      <p begin="00:28:29.930" end="00:28:34.340">and on prime data warehouse and pulling the data from the on prime warehouse using the movement service</p>
      <p begin="00:28:34.340" end="00:28:40.360">provided in the factory but just for simplicity ever move that from the demo for now so I've got a pipeline taking</p>
      <p begin="00:28:40.360" end="00:28:44.420">to datasets and producing one data set on the other side.</p>
      <p begin="00:28:44.420" end="00:28:47.880">What it's going to do is take those log files as I mentioned</p>
      <p begin="00:28:47.880" end="00:28:51.810">that is a bunch of log files for a month that describe all of the</p>
      <p begin="00:28:51.810" end="00:28:54.460">call activity it's going to...down to create,</p>
      <p begin="00:28:54.460" end="00:28:58.510">create one row for every customer and say, you know, okay,</p>
      <p begin="00:28:58.510" end="00:29:03.480">of all the logs are going to find all the records for mike we're going to generate one row for mike and say mike</p>
      <p begin="00:29:03.480" end="00:29:05.900">talked this many minutes in the monthly at this many drop</p>
      <p begin="00:29:05.900" end="00:29:11.870">calls etc we're going to combine it with the customer data so we can basically resolve...card id to</p>
      <p begin="00:29:11.870" end="00:29:16.560">an actual customer name and that's going to be done again by processing step in hd</p>
      <p begin="00:29:16.560" end="00:29:20.370">insight ...as a fantastic tool for running, you know,</p>
      <p begin="00:29:20.370" end="00:29:23.840">data chunking at scale so inside of this pipelines</p>
      <p begin="00:29:23.840" end="00:29:31.010">for edges double-click to have this open up I've got two steps?</p>
      <p begin="00:29:31.010" end="00:29:33.720">One is highly activity followed by</p>
      <p begin="00:29:33.720" end="00:29:38.690">copy activity copy activity I didn't really need to do I just did it to rename the file but the hide</p>
      <p begin="00:29:38.690" end="00:29:43.670">activities the meteor this is something that's going to be spun up to process all of those log</p>
      <p begin="00:29:43.670" end="00:29:48.600">files and aggregate the data basically what I'm doing is I'm preparing the data for input to</p>
      <p begin="00:29:48.600" end="00:29:54.510">a machine learning model if you want to look at the actual hives script that I'm running you</p>
      <p begin="00:29:54.510" end="00:29:58.940">can click pipeline source pipeline source will take you to definition of the</p>
      <p begin="00:29:58.940" end="00:30:03.920">pipeline and subsequently to hives script but if I double click on...here.</p>
      <p begin="00:30:03.920" end="00:30:06.730">And, I click activity script.</p>
      <p begin="00:30:06.730" end="00:30:09.480">You'll see this is just the typical</p>
      <p begin="00:30:09.480" end="00:30:13.770">...hives script that's going to be run to work with that the input</p>
      <p begin="00:30:13.770" end="00:30:18.940">datasets one interesting thing you can see is that hives script is parameterized just like</p>
      <p begin="00:30:18.940" end="00:30:21.770">you parameterized sequel the queries in</p>
      <p begin="00:30:21.770" end="00:30:27.100">app you parameterized the hives scripted take the frequency information like, you know,</p>
      <p begin="00:30:27.100" end="00:30:30.810">in this case we're running monthly so you take the fact that you know,</p>
      <p begin="00:30:30.810" end="00:30:34.480">what the years with the month etc you can download the high file</p>
      <p begin="00:30:34.480" end="00:30:39.940">etc if you're new to hire your new to duped there's a lot of other sessions at the conference that</p>
      <p begin="00:30:39.940" end="00:30:45.030">will talk you through and working through kind of all of the things you can do with the dupe and hd</p>
      <p begin="00:30:45.030" end="00:30:50.760">insight what I wanted to what I want you to take away from this talk is that you can use all of</p>
      <p begin="00:30:50.760" end="00:30:56.510">these services together into a pipelines I'm not a...into the high...too much detail?</p>
      <p begin="00:30:56.510" end="00:31:01.360">Lastly what I want to do is show you this particular pipeline stage</p>
      <p begin="00:31:01.360" end="00:31:07.480">and show you how you go about defining a pipeline in data factory so that you can see</p>
      <p begin="00:31:07.480" end="00:31:10.280">how these data sets are taken as input and</p>
      <p begin="00:31:10.280" end="00:31:15.280">then produces output so again if I double-click the pipeline I can go to</p>
      <p begin="00:31:15.280" end="00:31:20.420">pipeline source that will take you to the web-based editor for the jason document that</p>
      <p begin="00:31:20.420" end="00:31:26.340">represents the pipeline itself I've just copy this out into my sublime text</p>
      <p begin="00:31:26.340" end="00:31:30.390">here too so that we can look at it in that little bit higher.</p>
      <p begin="00:31:30.390" end="00:31:34.740">Vigor...so...drop this come over here and here's the</p>
      <p begin="00:31:34.740" end="00:31:40.220">pipeline definition so this is the definition for the pipeline we were just looking at.</p>
      <p begin="00:31:40.220" end="00:31:44.810">You just again it's a simple jason document is all you're doing is declaring that this</p>
      <p begin="00:31:44.810" end="00:31:49.700">data set is coming as input to this particular...task and it's going to produce this output</p>
      <p begin="00:31:49.700" end="00:31:53.870">so you just have to declare that the system what you do is you give it a name in this case I'm</p>
      <p begin="00:31:53.870" end="00:31:57.680">saying aggregate mobile customer usage some aggregating those logs</p>
      <p begin="00:31:57.680" end="00:32:01.550">...the description I said a start inundate this is just like scheduling</p>
      <p begin="00:32:01.550" end="00:32:05.240">...meeting you say are the recording meeting is going to start january</p>
      <p begin="00:32:05.240" end="00:32:10.360">...in december but it's going to happen monthly so, you know,...btwelve instances of that meeting</p>
      <p begin="00:32:11.440" end="00:32:14.640">...the year and then lastly what you do is there's an array and</p>
      <p begin="00:32:14.640" end="00:32:19.340">there's one object in the array for each step of the pipeline so in this particular case I've</p>
      <p begin="00:32:19.340" end="00:32:24.590">got, you know, ...exploit the whole thing into a few pipelines so let's</p>
      <p begin="00:32:24.590" end="00:32:28.870">to drill nc what one step in a pipeline looks like.</p>
      <p begin="00:32:28.870" end="00:32:33.210">And, again, one step is suggestion object and the first thing I do is I name my step and</p>
      <p begin="00:32:33.210" end="00:32:38.060">...can be aggregate more mobileusage minutes that step is an hd</p>
      <p begin="00:32:38.060" end="00:32:43.040">inside activity it's going to run on the hd insight cluster that's represented by this</p>
      <p begin="00:32:43.040" end="00:32:49.200">...service I'll come back to how you define...service and just a second and what actually is going to run is a</p>
      <p begin="00:32:49.200" end="00:32:52.620">hype script that's located at this location in lobster?</p>
      <p begin="00:32:53.770" end="00:32:57.380">And, this is the blob...located at and these are all the additional</p>
      <p begin="00:32:57.380" end="00:33:01.550">...I want to have automatically bound to my who cluster when this particular</p>
      <p begin="00:33:01.550" end="00:33:06.520">...activity runs there's a lot of configuration you can do here I've showed a little bit of the our</p>
      <p begin="00:33:06.520" end="00:33:12.250">there's a lot more so, you effectively saying run this...script once a month on that</p>
      <p begin="00:33:12.250" end="00:33:15.500">input data and there's a section called extended properties</p>
      <p begin="00:33:15.500" end="00:33:20.080">extended properties are just any variables you want to pass in to your particular hype</p>
      <p begin="00:33:20.080" end="00:33:26.190">scripts execution so each time it executes in this case what's monthly these extend properties</p>
      <p begin="00:33:26.190" end="00:33:30.820">would passed in I...the defined a bunch of them here.</p>
      <p begin="00:33:30.820" end="00:33:33.710">And, you can see what I'm passing in here is your</p>
      <p begin="00:33:33.710" end="00:33:37.430">...day and I'm taking that from the slice start</p>
      <p begin="00:33:37.430" end="00:33:42.290">variable that's kind of an environment variable that's injected by data factory...into the</p>
      <p begin="00:33:42.290" end="00:33:47.110">hives script the fact that hey you're running for the january run of twenty fifteen</p>
      <p begin="00:33:47.110" end="00:33:53.070">right now so I can parameterized my hype...take that is input lastly...specify the to</p>
      <p begin="00:33:53.070" end="00:33:57.980">datasets that will be used as input the reason we have this level of specification is because we can</p>
      <p begin="00:33:57.980" end="00:34:01.660">do interesting things like automatically do precondition checking on those</p>
      <p begin="00:34:01.660" end="00:34:06.570">datasets to cr they available are the meeting certain preconditions so we don't waste time</p>
      <p begin="00:34:06.570" end="00:34:10.530">and resources spinning up hd insight work if the input data just</p>
      <p begin="00:34:10.530" end="00:34:15.520">isn't ready or it's not matching certain preconditions that you specified I'll talk about preconditions a little bit later in the</p>
      <p begin="00:34:15.520" end="00:34:20.349">top and then lastly you say output well this is what the output of the</p>
      <p begin="00:34:20.349" end="00:34:24.319">hives script is actually going to generate it's another data set and blobs.</p>
      <p begin="00:34:24.319" end="00:34:29.759">then we've got a set of policies you...state for that activity I put the simplest policy here which</p>
      <p begin="00:34:29.759" end="00:34:33.859">is to retry policy which means when we spin up that activity this</p>
      <p begin="00:34:33.859" end="00:34:36.299">...script and run it if it fails you want</p>
      <p begin="00:34:36.299" end="00:34:41.229">to retry for-you if so will retry the activity you can do all kinds of things here like</p>
      <p begin="00:34:41.229" end="00:34:45.749">have timed back-office and when you want to retry you can specify what to do</p>
      <p begin="00:34:45.749" end="00:34:49.619">and data arrives later than you expect so let's say you go and</p>
      <p begin="00:34:49.619" end="00:34:54.499">want to run at the end of every month but a certain amount of input data is available you can give us all</p>
      <p begin="00:34:54.499" end="00:34:59.810">kinds of policy that you want to do and how and when we run these activities for you?</p>
      <p begin="00:34:59.810" end="00:35:03.470">And, then I've got another activity along the way as well.</p>
      <p begin="00:35:03.470" end="00:35:06.140">So, that's how you go about specifying a pipeline it's just a jason</p>
      <p begin="00:35:06.140" end="00:35:11.040">the document one object for every activity and you just declare what activities you want to have run</p>
      <p begin="00:35:11.040" end="00:35:15.810">...where you want to run them I'm going to go back to this...service line which was saying run</p>
      <p begin="00:35:15.810" end="00:35:20.120">this hives script on this hd insight cluster.</p>
      <p begin="00:35:20.120" end="00:35:24.600">And, this hd insight clusters defined by...service links service again is just a simple</p>
      <p begin="00:35:24.600" end="00:35:29.830">jason document and what you're seeing here is going to run on this html</p>
      <p begin="00:35:29.830" end="00:35:34.520">...cluster I want the cluster to be hd insight version three-point-one I want</p>
      <p begin="00:35:34.520" end="00:35:35.290">the cluster size</p>
      <p begin="00:35:35.290" end="00:35:39.880">...nodes are two hundred nodes or whatever you choose basically any configuration</p>
      <p begin="00:35:39.880" end="00:35:44.840">you'd want about your eighteenth site service and then lastly?</p>
      <p begin="00:35:46.020" end="00:35:51.070">We specify type anti peer could mean one of two things you can for a lot of</p>
      <p begin="00:35:51.070" end="00:35:54.810">our processing services that we support data factory we have one of to modes the first</p>
      <p begin="00:35:54.810" end="00:35:58.760">mode is you've created the resource up-front...effectively given a</p>
      <p begin="00:35:58.760" end="00:36:03.720">...string to data factory and you said go and use this resource so in this case you would have created</p>
      <p begin="00:36:03.720" end="00:36:09.140">your hd insight...cluster and you give us the connection string over in this particular case</p>
      <p begin="00:36:09.140" end="00:36:13.620">...specified is to use what we call our on-demand html</p>
      <p begin="00:36:13.620" end="00:36:18.050">site feature on-demand means let data factory take care of provisioning</p>
      <p begin="00:36:18.050" end="00:36:23.160">...do cluster for you when it's needed and the provisioning when it's not needed so you can now start to</p>
      <p begin="00:36:23.160" end="00:36:27.180">create these pipelines that use hd insight use virtual machines to run custom code</p>
      <p begin="00:36:27.180" end="00:36:31.380">...and the pipeline will take care of provisioning the infrastructure</p>
      <p begin="00:36:31.380" end="00:36:34.690">two-run that script when needed and the provisioning the infrastructure</p>
      <p begin="00:36:34.690" end="00:36:38.650">when not needed to completely out of the business of any kind of infrastructure management of</p>
      <p begin="00:36:38.650" end="00:36:43.000">...clusters and gm's and whatnot you just give us code you want to run</p>
      <p begin="00:36:43.000" end="00:36:47.920">and where you want to run it and we take care of...it up...it down on your behalf if we need to retry we go get</p>
      <p begin="00:36:47.920" end="00:36:52.300">it back etc so it's a nice feature from that perspective it really gets you kind of</p>
      <p begin="00:36:52.300" end="00:36:57.390">...focus on the various processing steps you want to have happen?</p>
      <p begin="00:36:57.390" end="00:37:02.210">So, let me jump back out into...into our pipeline again so</p>
      <p begin="00:37:02.210" end="00:37:07.300">we've got incoming log data we got customer data we've merged it we produced another</p>
      <p begin="00:37:07.300" end="00:37:11.930">data set which is basically one row for every customer for that month.</p>
      <p begin="00:37:11.930" end="00:37:14.630">And, then lastly I want to show you two more steps</p>
      <p begin="00:37:15.960" end="00:37:19.940">is going to take that data set in blob store that's one row for</p>
      <p begin="00:37:19.940" end="00:37:24.560">...month and I'm going to feed it into a pipeline that has one activity and it</p>
      <p begin="00:37:24.560" end="00:37:28.100">if I double-click you can see down below.</p>
      <p begin="00:37:29.150" end="00:37:34.090">What's actually running inside of that pipeline is an activity but this time it's an activity</p>
      <p begin="00:37:34.090" end="00:37:39.740">that's going to call and as your machine learning model so just like in the prior pipeline we were using the</p>
      <p begin="00:37:39.740" end="00:37:43.990">...service to run some hd insight prepare and aggregate data this time we're going to</p>
      <p begin="00:37:43.990" end="00:37:48.000">call-in as your machine learning model and say hey the output of that</p>
      <p begin="00:37:48.000" end="00:37:52.770">whooped job what's that's ready I want you to feed that into a machine learning model and</p>
      <p begin="00:37:52.770" end="00:37:57.270">that machine learning models going-to-take that output effectively add one column the likelihood of that</p>
      <p begin="00:37:57.270" end="00:38:01.570">customer to churn and the way that all that works.</p>
      <p begin="00:38:01.570" end="00:38:04.430">Is by using...of the machine learning models</p>
      <p begin="00:38:04.430" end="00:38:08.830">...available in the machine learning gallery lone</p>
      <p begin="00:38:08.830" end="00:38:12.140">...for this demonstration called delco customer churn it's</p>
      <p begin="00:38:12.140" end="00:38:17.280">...machine learning model that looks like this you probably saw it machine learning introduced by joseph</p>
      <p begin="00:38:17.280" end="00:38:21.480">in the...earlier today this is a model that's been built to</p>
      <p begin="00:38:21.480" end="00:38:24.740">and built-in trained based on</p>
      <p begin="00:38:24.740" end="00:38:28.590">...togo usage logs so the idea is that you can feed logs</p>
      <p begin="00:38:28.590" end="00:38:33.470">to this model and it will with pretty good accuracy determine is this customer likely</p>
      <p begin="00:38:33.470" end="00:38:38.330">to cancel their subscription or use less based on the training data that was fed</p>
      <p begin="00:38:38.330" end="00:38:39.940">...this model the training data is</p>
      <p begin="00:38:39.940" end="00:38:44.960">effectively data of logs of customers that actually cancel their...less so</p>
      <p begin="00:38:44.960" end="00:38:51.730">use that pattern that recognition to figure out what which customers are likely to</p>
      <p begin="00:38:51.730" end="00:38:56.720">churn so I'm certainly not a data scientist...I'm not going to walk through what all</p>
      <p begin="00:38:56.720" end="00:39:02.970">the steps are within this model but the idea is that?</p>
      <p begin="00:39:02.970" end="00:39:07.940">As a developer what you can do is you can work with the various models that are available</p>
      <p begin="00:39:07.940" end="00:39:12.850">compose them into your data factory pipelines and use them just as</p>
      <p begin="00:39:12.850" end="00:39:16.340">a web service so the way we actually built this is we had one of the data</p>
      <p begin="00:39:16.340" end="00:39:19.150">scientists go create this model for us and he tuned it and,</p>
      <p begin="00:39:19.150" end="00:39:24.480">... I he tells me it's very accurate and then he goes</p>
      <p begin="00:39:24.480" end="00:39:28.490">any prepares this model as a web services joseph showed in the keynote and then as</p>
      <p begin="00:39:28.490" end="00:39:33.400">a developer I can just use this by calling the web service and the way it works is</p>
      <p begin="00:39:33.400" end="00:39:37.870">that using a batch scoring approach which what that means from the machine learning perspective</p>
      <p begin="00:39:37.870" end="00:39:42.660">is that I call the web service and I tell the web service...in blob storage the</p>
      <p begin="00:39:42.660" end="00:39:47.630">input data is so I don't shuffle the data to the web service over http or anything like that</p>
      <p begin="00:39:47.630" end="00:39:51.280">simply call the web service and say please score all the data in this</p>
      <p begin="00:39:51.280" end="00:39:55.570">...in this file in blob storage and put the output over here so that</p>
      <p begin="00:39:55.570" end="00:39:59.840">capability is natively built into...once you once you create a web service</p>
      <p begin="00:39:59.840" end="00:40:04.080">based on your model so as a developer I didn't need to know all of the to class</p>
      <p begin="00:40:04.080" end="00:40:08.550">...support the imagers that are going on here instead I needed to know</p>
      <p begin="00:40:08.550" end="00:40:14.440">how to call that machine learning model and the schema of the input data that was required so from</p>
      <p begin="00:40:14.440" end="00:40:18.890">a data factory perspective I just added in this step to call that</p>
      <p begin="00:40:18.890" end="00:40:25.370">model and I tool that take the data from this blob store write your output to this blob store.</p>
      <p begin="00:40:25.370" end="00:40:26.840">And, then lastly.</p>
      <p begin="00:40:26.840" end="00:40:29.920">I created a step that said copy the data from</p>
      <p begin="00:40:29.920" end="00:40:34.410">sorry about that copy the data from blob storage to</p>
      <p begin="00:40:34.410" end="00:40:38.240">sequel db okay so you can see on this side the</p>
      <p begin="00:40:38.240" end="00:40:42.000">...blob store on this side it's the same data that I moving over to sequel</p>
      <p begin="00:40:42.000" end="00:40:46.950">db now that I've created that interesting results...that is telling me the customers that are likely to</p>
      <p begin="00:40:46.950" end="00:40:53.220">churn is one thing I want to show you about that copy activity and then we'll look at the actual data this</p>
      <p begin="00:40:53.220" end="00:40:59.140">copy activity interesting is what's actually performing the copy under the covers</p>
      <p begin="00:40:59.140" end="00:41:03.650">what inside of the data factory service we have a globally available copy service that</p>
      <p begin="00:41:03.650" end="00:41:09.500">basically moves data among as your stores from on prime to asher et cetera so,</p>
      <p begin="00:41:09.500" end="00:41:13.020">that all you need to do to specify data movement is to</p>
      <p begin="00:41:13.020" end="00:41:17.990">common say well it's this data as input and I want this thing is output maybe in this case from</p>
      <p begin="00:41:17.990" end="00:41:20.470">blob the sequel and you don't worry about spinning up</p>
      <p begin="00:41:20.470" end="00:41:24.700">gm's when the copy will happen retrying the copy the system just takes care of it for</p>
      <p begin="00:41:24.700" end="00:41:29.110">you so the copy in this case is a...saying this data set is input this</p>
      <p begin="00:41:29.110" end="00:41:33.270">...output go and if you want to do some type of projection during the</p>
      <p begin="00:41:33.270" end="00:41:36.390">copy like hayley take these three columns from the</p>
      <p begin="00:41:36.390" end="00:41:40.530">input set and put them over here you can you can specify that projection just in the</p>
      <p begin="00:41:40.530" end="00:41:45.240">jason document in this case I'm just doing a straight copy so I'm saying the sources blob</p>
      <p begin="00:41:45.240" end="00:41:50.150">storage skip the first-line because I've got headers in the first-line and the destination is</p>
      <p begin="00:41:50.150" end="00:41:54.800">as your sequel and actually call this stored product on the way integer sequels I want</p>
      <p begin="00:41:54.800" end="00:42:00.620">that to be called instead of directly writing in and here's the input and output data set and I just put that into my</p>
      <p begin="00:42:00.620" end="00:42:06.910">pipeline the copy happens for me so it's a nice facility that's offered insider data factory.</p>
      <p begin="00:42:06.910" end="00:42:10.270">So, now if this thing all runs end-to-end nicely like it's</p>
      <p begin="00:42:10.270" end="00:42:14.970">supposed to each month what I should be doing is going from the data that looks</p>
      <p begin="00:42:14.970" end="00:42:19.910">like that and that structure customer data to some structured piece</p>
      <p begin="00:42:19.910" end="00:42:24.930">of data that includes the likelihood ofchurn for each customer so</p>
      <p begin="00:42:24.930" end="00:42:31.120">if you recall here are output is a data set in sql if I connect</p>
      <p begin="00:42:31.120" end="00:42:36.070">to that database and run a query against that table that's being copied to</p>
      <p begin="00:42:36.070" end="00:42:40.790">by the pipeline and I select out a few the columns and the last column</p>
      <p begin="00:42:40.790" end="00:42:47.100">selecting out is scored probability this is the...that's added by the machine learning model what</p>
      <p begin="00:42:47.100" end="00:42:50.590">effectively done is I've aggregated all that log data</p>
      <p begin="00:42:50.590" end="00:42:55.990">...predicted using the ml model and this is the output</p>
      <p begin="00:42:55.990" end="00:43:00.280">and,... to data people this is a...good...will look at how to get reports</p>
      <p begin="00:43:00.280" end="00:43:05.140">and second so what you've got here is this data was coming from that structured data</p>
      <p begin="00:43:05.140" end="00:43:09.130">the customer list this data is a bunch of aggregation that came from the</p>
      <p begin="00:43:09.130" end="00:43:15.030">logs themselves and this particular data is data that came from the machine</p>
      <p begin="00:43:15.030" end="00:43:19.970">learning model itself so effectively what it's saying is customer seven two nine six three of age</p>
      <p begin="00:43:19.970" end="00:43:24.250">seventy-nine is a female she had a six percent drop call rate that month</p>
      <p begin="00:43:24.250" end="00:43:29.150">...one percent failure rate that...talked eighty-one minutes and she has a ninety percent likelihood of</p>
      <p begin="00:43:29.150" end="00:43:33.990">churning and it's not just these factors that went into the model but I've just select about these</p>
      <p begin="00:43:33.990" end="00:43:40.540">three so that you can kinda see the structured results that came out the other side into the db so</p>
      <p begin="00:43:40.540" end="00:43:45.080">what I want you to take away from one of these pipelines is that the idea is being able to</p>
      <p begin="00:43:45.080" end="00:43:49.900">work with and collect all of the interesting data use the appropriate as your service of</p>
      <p begin="00:43:49.900" end="00:43:53.210">choice to operate in transform on that data whether it's</p>
      <p begin="00:43:53.210" end="00:43:55.520">...dupe custom code on ibm as</p>
      <p begin="00:43:55.520" end="00:44:00.940">...ml etc and then push that data to the store or place</p>
      <p begin="00:44:00.940" end="00:44:05.160">...can most easily be consumed...have that run consistently you know,</p>
      <p begin="00:44:05.160" end="00:44:09.830">our in our out every month every week whatever the cycle is that makes sense for you in this case we've</p>
      <p begin="00:44:09.830" end="00:44:15.400">got this thing running monthly and then lastly want obviously once you've got something into a nice structured</p>
      <p begin="00:44:15.400" end="00:44:21.480">form like this you can go in create snazzy looking reports that.</p>
      <p begin="00:44:21.480" end="00:44:25.610">Represents all that data so we quickly when created one that was a our</p>
      <p begin="00:44:25.610" end="00:44:32.590">...visualization our buys one of our new analysis tools and all</p>
      <p begin="00:44:32.590" end="00:44:37.550">I've done is graft that customer turn data so I can drill in is just talking to the</p>
      <p begin="00:44:37.550" end="00:44:42.910">database that that's being updated by the pipeline and I can say good most of my customers</p>
      <p begin="00:44:42.910" end="00:44:47.810">in blue here aren't likely to churn but the ones in purple are likely to churn let's kind of</p>
      <p begin="00:44:47.810" end="00:44:52.770">drilling and figure out why that might be well it turns out there's nothing to do with the type of job they have</p>
      <p begin="00:44:52.770" end="00:44:57.180">actually has nothing to do type of education they have but people in,</p>
      <p begin="00:44:57.180" end="00:45:01.560">you know,...this particular state seem to be showing</p>
      <p begin="00:45:01.560" end="00:45:06.430">more likelihood then this other states let's start drilling in there and seeing what was happening maybe in the infrastructure</p>
      <p begin="00:45:06.430" end="00:45:11.250">in that place you can start to drill in get more insight into what was happening what was causing these people</p>
      <p begin="00:45:11.250" end="00:45:17.860">start...and you can visualize that data in interesting ways with rbi but from a analytics</p>
      <p begin="00:45:17.860" end="00:45:23.350">perspective want to take away is that you can build these pipelines you can operate</p>
      <p begin="00:45:23.350" end="00:45:28.340">them you can get kind of a complete end-to-end view of the data and then</p>
      <p begin="00:45:30.380" end="00:45:34.140">you...them...regular basis...jump back into.</p>
      <p begin="00:45:34.140" end="00:45:39.220">...slides here.</p>
      <p begin="00:45:39.220" end="00:45:43.180">I'll skip this one will quickly and give you a quick summary of</p>
      <p begin="00:45:43.180" end="00:45:49.220">data factory what it's a service to let-you orchestrate schedule and monitorexisting</p>
      <p begin="00:45:49.220" end="00:45:53.800">as your services so you can compose them together to create pipelines like this it</p>
      <p begin="00:45:53.800" end="00:45:58.800">does automatic infrastructure management I showed it for...quickly you'll see it coming for custom code on</p>
      <p begin="00:45:58.800" end="00:46:01.480">...m it has a movement service built into it</p>
      <p begin="00:46:01.480" end="00:46:05.720">...easily facilitate movement among your various stores both on</p>
      <p begin="00:46:05.720" end="00:46:10.150">...will be adding ever new connectors each month we just finished adding the oracle connector and the on</p>
      <p begin="00:46:10.150" end="00:46:15.440">profile share connector and, then lastly provides you a single pane of glass one place to log</p>
      <p begin="00:46:15.440" end="00:46:19.880">into to see how your data is moving how it's being transformed how things are going and I'll</p>
      <p begin="00:46:19.880" end="00:46:27.060">show you an example of that in a little larger data factory in just a second.</p>
      <p begin="00:46:27.060" end="00:46:29.740">In terms of a few other scenarios that we've been</p>
      <p begin="00:46:29.740" end="00:46:34.610">seeing people wanting to build-out these types of analytics pipelines are things from</p>
      <p begin="00:46:34.610" end="00:46:39.600">generating product recommendations for websites if you were in one of the earlier modern data</p>
      <p begin="00:46:39.600" end="00:46:43.980">talks you saw how big data was being used to augment the search results...as</p>
      <p begin="00:46:43.980" end="00:46:48.960">...search index typically you'd be running that on a schedule every day all the time to</p>
      <p begin="00:46:48.960" end="00:46:53.470">be...the data for those search results another class of usage that we see a</p>
      <p begin="00:46:53.470" end="00:46:58.220">lot is what we call operational excellence scenarios where people are building telemetry</p>
      <p begin="00:46:58.220" end="00:47:06.460">systems where if you think about any kind of sas application or, you know,</p>
      <p begin="00:47:06.460" end="00:47:09.400">device that you might be monitoring devices are constantly</p>
      <p begin="00:47:09.400" end="00:47:14.070">emitting all kinds of data and information that you need to aggregate</p>
      <p begin="00:47:14.070" end="00:47:19.030">predict on etc to determine what's availability of your services whatever latency</p>
      <p begin="00:47:19.030" end="00:47:22.860">...customers doing with it etc so we see a lot of us</p>
      <p begin="00:47:22.860" end="00:47:26.840">asks the application builders through to industrial automation</p>
      <p begin="00:47:26.840" end="00:47:31.080">companies using data factory and lobster and html.</p>
      <p begin="00:47:31.080" end="00:47:34.710">To ingest all of the telemetry information from their website</p>
      <p begin="00:47:34.710" end="00:47:39.230">through to their oil and gas pipeline and then creating just series of</p>
      <p begin="00:47:39.230" end="00:47:43.930">...pipelines to work on that data transform that data give you different views</p>
      <p begin="00:47:43.930" end="00:47:50.350">over it going to get more insight out of out of the systems...what I want to do is login</p>
      <p begin="00:47:50.350" end="00:47:55.040">...other data factory that represents one of these telemetry systems to give you</p>
      <p begin="00:47:55.040" end="00:48:02.800">an idea of the types of things you can doas these as the system start to grow up.</p>
      <p begin="00:48:02.800" end="00:48:05.690">Great we're back so let me jump out of this customer</p>
      <p begin="00:48:05.690" end="00:48:16.040">turn demonstration and jump into a different one I'm going to call the data factory data lake.</p>
      <p begin="00:48:16.040" end="00:48:21.610">You can use one's a little bigger it's got a hundred-fifty for datasets and it let's go to the diagram.</p>
      <p begin="00:48:21.610" end="00:48:25.150">What this is actually this is the data factory we use to</p>
      <p begin="00:48:25.150" end="00:48:29.880">run data factory so worldwide this data factory services up</p>
      <p begin="00:48:29.880" end="00:48:33.020">...collecting logs all the time about what pipelines were running</p>
      <p begin="00:48:33.020" end="00:48:36.820">were orchestrating what's up what's down and we use</p>
      <p begin="00:48:36.820" end="00:48:40.660">a data factory to ingest all kinds of telemetry from commerce telemetry through</p>
      <p begin="00:48:40.660" end="00:48:45.540">...usage telemetry to our live site telemetry and we munch all that together to figure out what</p>
      <p begin="00:48:45.540" end="00:48:49.370">our users are doing what they're experiences like what's working well what's not working</p>
      <p begin="00:48:49.370" end="00:48:52.430">well etc effectively how we run and operate data</p>
      <p begin="00:48:52.430" end="00:48:58.480">...service itself a lot of other as your services and microsoft services do the same and,</p>
      <p begin="00:48:58.480" end="00:49:01.840">what I want to show you?</p>
      <p begin="00:49:01.840" end="00:49:06.640">In this factory is how these things kinda grow up over...</p>
      <p begin="00:49:06.640" end="00:49:12.520">this particular factories actually not that old there's a lot of stuff going on here some people say</p>
      <p begin="00:49:12.520" end="00:49:17.320">man that looks ugly...did you laid out like that like these lines go over well turns out this is the way</p>
      <p begin="00:49:17.320" end="00:49:22.370">our telemetry team likes it laid out it makes sense to...we're trying to do with data factory is give you</p>
      <p begin="00:49:22.370" end="00:49:26.360">a effectively alive visio canvas or live diagram of exactly</p>
      <p begin="00:49:26.360" end="00:49:31.890">what's deployed how things relate to each other and let you organize...</p>
      <p begin="00:49:31.890" end="00:49:36.660"> collapse it expand it however you see fit so garner the days when you decide</p>
      <p begin="00:49:36.660" end="00:49:41.490">to...design...data integration project gets written on the whiteboard or</p>
      <p begin="00:49:41.490" end="00:49:45.840">put...visio document of some kind and that's the last time you ever see a pictorial representation that's up</p>
      <p begin="00:49:45.840" end="00:49:51.450">to date with data factory what we're trying to do is say you've got a live diagram of all of</p>
      <p begin="00:49:51.450" end="00:49:56.230">your data integration overlaid with health information and usage information that you can log</p>
      <p begin="00:49:56.230" end="00:50:01.140">into you can customize it's...to however makes sense for you it's yours but it's up</p>
      <p begin="00:50:01.140" end="00:50:04.510">to date it's live it's an accurate representation of the system.</p>
      <p begin="00:50:04.510" end="00:50:07.750">If I drill in you can see well I've got some</p>
      <p begin="00:50:07.750" end="00:50:12.510">stuff that's read something in our telemetry system's not working well you can maybe ask me wired which is</p>
      <p begin="00:50:12.510" end="00:50:16.180">...read but that's a conversation for another day and,</p>
      <p begin="00:50:16.180" end="00:50:20.940">I can start now to kind of added glance drill in and say hey through this fairly complex network of</p>
      <p begin="00:50:20.940" end="00:50:29.170">pipelines what's going on so if I drill in to one of these.</p>
      <p begin="00:50:29.170" end="00:50:40.410">One of these ...the datasets here.</p>
      <p begin="00:50:40.410" end="00:50:43.920">And, you can see this particular data set it really hasn't had one of</p>
      <p begin="00:50:43.920" end="00:50:47.510">its time slices be for fielding quite some time so you ends kind of</p>
      <p begin="00:50:47.510" end="00:50:54.850">look at what's going on here so by drill into one of these.</p>
      <p begin="00:50:54.850" end="00:50:58.560">You can see we've had a bunch of retry...the systems done for me automatically every one of those</p>
      <p begin="00:50:58.560" end="00:51:03.080">of failed and their statuses fail validation and...message says a</p>
      <p begin="00:51:03.080" end="00:51:07.750">blob at this particular location does not exist that's pretty small I dunno...everybody can see it as a</p>
      <p begin="00:51:07.750" end="00:51:12.490">blob at this very particular location doesn't exist this is just showing you some of</p>
      <p begin="00:51:12.490" end="00:51:16.680">the simple validation that are available data factory where you can say look I need</p>
      <p begin="00:51:16.680" end="00:51:21.330">this input data I'm going to ingested into my pipeline if it's not there or</p>
      <p begin="00:51:21.330" end="00:51:26.140">...smaller than a particular size or hasn't been updated since a certain date then it's not</p>
      <p begin="00:51:26.140" end="00:51:30.140">needs useful to me so don't even start running the pipeline just fail validation</p>
      <p begin="00:51:30.140" end="00:51:35.060">up-front something's wrong so in this particular case we're expecting a partner team to be putting a file</p>
      <p begin="00:51:35.060" end="00:51:40.090">there for us to consume that file hasn't been put there for a while so the pipeline is</p>
      <p begin="00:51:40.090" end="00:51:45.070">not starting it's failing validation in alerts get sent to us automatically that particular stage in my pipeline</p>
      <p begin="00:51:45.070" end="00:51:50.780">is failed once that stage gets fulfilled in the condition gets met data factory has a bunch of features for</p>
      <p begin="00:51:50.780" end="00:51:54.540">...can come in and say okay rerun that pipeline as if it was,</p>
      <p begin="00:51:54.540" end="00:51:58.710">you know, three days ago when it started failing and then cascade that all the way down so</p>
      <p begin="00:51:58.710" end="00:52:04.270">anything else that's waiting on that gets kicked off as needed when needed et cetera so,</p>
      <p begin="00:52:04.270" end="00:52:09.000">there's a lot of nice features built-in factory so that you can kind of manage a larger data</p>
      <p begin="00:52:09.000" end="00:52:15.160">...for a larger telemetry system like this so that was just a quick look at</p>
      <p begin="00:52:15.160" end="00:52:18.580">of what a larger system starts to grow up into and again this</p>
      <p begin="00:52:18.580" end="00:52:23.960">...a system that you can customize so if I take a lock off I can start to</p>
      <p begin="00:52:23.960" end="00:52:28.530">drag things around and...it my own multiple people can at the surface however</p>
      <p begin="00:52:28.530" end="00:52:40.760">they see fit I will undo that because people get mad at me when I change their work?</p>
      <p begin="00:52:40.760" end="00:52:46.040">There's a question that said I print that today we don't have a feature in-box that we're going to</p>
      <p begin="00:52:46.040" end="00:52:50.600">printed layout nicely ...one we've heard a lot those so we'll look at doing an</p>
      <p begin="00:52:50.600" end="00:52:54.450">...for print and in some.</p>
      <p begin="00:52:54.450" end="00:52:58.740">So, that showed you a couple other factories really quickly.</p>
      <p begin="00:52:58.740" end="00:53:04.790">Let me now jump back to slide's...got a couple minutes left.</p>
      <p begin="00:53:04.790" end="00:53:08.560">Need to be...can't see the time thing.</p>
      <p begin="00:53:08.560" end="00:53:14.490">Clearly wasn't...stage made for me all right so in terms of</p>
      <p begin="00:53:14.490" end="00:53:18.430">road map I showed you a little bit about what data...can be that can do</p>
      <p begin="00:53:18.430" end="00:53:23.350">for-you today how to create pipelines things that you'll see coming in this area in the</p>
      <p begin="00:53:23.350" end="00:53:26.730">future is that you get a lot more authoring support you'll</p>
      <p begin="00:53:26.730" end="00:53:31.690">see visual studio integration you'll see pipeline templates you can create pipelines like the</p>
      <p begin="00:53:31.690" end="00:53:37.010">one I showed from a template and then just fill in the missing pieces you'll see a</p>
      <p begin="00:53:37.010" end="00:53:41.130">lot more connectors coming to data factory there's some coming in the coming weeks</p>
      <p begin="00:53:41.130" end="00:53:45.400">...be adding them weekly from here out there's connectors coming</p>
      <p begin="00:53:45.400" end="00:53:50.210">...document to be search sequel...data lake all the stuff that you've heard about you can efficiently</p>
      <p begin="00:53:50.210" end="00:53:53.560">move data among these sources and create pipelines that...them</p>
      <p begin="00:53:55.170" end="00:54:00.270">...be additional activities so that you can execute stored...dw</p>
      <p begin="00:54:00.270" end="00:54:04.860">through a bunch of interesting stuff coming in that space there's some work will do to make it easier to</p>
      <p begin="00:54:04.860" end="00:54:11.210">handle reference data like that customer list we were looking at there's a bunch that's coming in</p>
      <p begin="00:54:11.210" end="00:54:15.870">terms of improving and adding to that monitoring view so you can really have a single pane</p>
      <p begin="00:54:15.870" end="00:54:22.450">of glass to see how your data is moving how it's being transformed whether it's healthy or not.</p>
      <p begin="00:54:22.450" end="00:54:27.280">And, then lastly what I showed you today with how to create a pipeline</p>
      <p begin="00:54:27.280" end="00:54:32.180">that...a lot of processing services in manager a lot of the storage systems and measure but</p>
      <p begin="00:54:32.180" end="00:54:37.170">we're opening up the entire system of data factory so that if you want to go and</p>
      <p begin="00:54:37.170" end="00:54:38.940">...in a new processing</p>
      <p begin="00:54:38.940" end="00:54:43.100">system what I mean by processing system is something like hd inside or something like as your</p>
      <p begin="00:54:43.100" end="00:54:47.910">...you can go add your own you can go adds support for your own so we're working with</p>
      <p begin="00:54:47.910" end="00:54:52.740">partners right now that have spark as a service and other processing platforms</p>
      <p begin="00:54:52.740" end="00:54:57.140">and they're adding support for those platforms into factory so you can create pipelines that</p>
      <p begin="00:54:57.140" end="00:54:59.980">...all kinds of different systems to</p>
      <p begin="00:54:59.980" end="00:55:04.870">basically use the right tool for the job for very for your various tasks and easily</p>
      <p begin="00:55:04.870" end="00:55:09.540">stitched together or compose these various systems into a pipeline so the be and extensibility</p>
      <p begin="00:55:09.540" end="00:55:14.200">sdk that will release its already available in limited preview right now as I mentioned or working</p>
      <p begin="00:55:14.200" end="00:55:18.690">at various partners that both have systems on prime and in the cloud so you'll be able</p>
      <p begin="00:55:18.690" end="00:55:24.690">to truly create hybrid pipelines and managing monitor them from one place and,...</p>
      <p begin="00:55:24.690" end="00:55:29.110">that's an exciting new area that's coming in data factor you just kind of what your appetite</p>
      <p begin="00:55:29.110" end="00:55:33.120">...if you're interested in learning more about that feel free to ping me and then lastly</p>
      <p begin="00:55:33.120" end="00:55:37.910">geo location today you can create...data factory in one of the...geo location...of the as</p>
      <p begin="00:55:37.910" end="00:55:44.070">your regions from that region you can orchestrate things across all of the rest so you can create</p>
      <p begin="00:55:44.070" end="00:55:49.060">a pipeline that works across all the regions today you'll see data factory the orchestrate</p>
      <p begin="00:55:49.060" end="00:55:54.310">a of data factory be available other regions in the coming months as well.</p>
      <p begin="00:55:54.310" end="00:55:58.090">With that I thought I provide a few resources is one of the first</p>
      <p begin="00:55:58.090" end="00:56:02.530">sessions we've done on data factory and how it can combine so we tried to do is</p>
      <p begin="00:56:02.530" end="00:56:06.040">provide a lot of resources if you're interested to dig in and learn more hopefully it</p>
      <p begin="00:56:06.040" end="00:56:10.710">kind of whet your appetite for things you can do there's a lot of good documentation windows</p>
      <p begin="00:56:10.710" end="00:56:15.490">...dot com we've got to get hub repo just for data factory samples we</p>
      <p begin="00:56:15.490" end="00:56:20.600">are all years on what you'd like to see for samples we've uploaded some we change them all the time we'll</p>
      <p begin="00:56:20.600" end="00:56:27.100">probably put this customer churn example up there as well in the coming week there's a place to ask questions</p>
      <p begin="00:56:27.100" end="00:56:32.230">...a place to ask for new features there's a lot of financial services companies you can</p>
      <p begin="00:56:32.230" end="00:56:37.220">imagine do all kinds of interesting things with data we've taken the best of what we've learned from them so far with</p>
      <p begin="00:56:37.220" end="00:56:41.440">...that in architectural pattern we call a blueprint that's going to be</p>
      <p begin="00:56:41.440" end="00:56:46.000">published later this week so-if you want-to see what some of our customers like millman is</p>
      <p begin="00:56:46.000" end="00:56:50.930">doing in terms of actuarial automation using data factory and html...</p>
      <p begin="00:56:50.930" end="00:56:56.410">store you'll be able to...the best practices we've extracted from that there's a set of other case studies available here</p>
      <p begin="00:56:56.410" end="00:57:01.340">on what customers are doing to create analytics pipelines using as your today with...you know,</p>
      <p begin="00:57:01.340" end="00:57:06.070">a lot more to come one thing all note is that data factors currently in preview we have a number of</p>
      <p begin="00:57:06.070" end="00:57:11.730">customers running and production already it's a service we've been running inside of microsoft for a while</p>
      <p begin="00:57:11.730" end="00:57:16.430">now running production loads for some of our biggest services whether it's xbox microsoft</p>
      <p begin="00:57:16.430" end="00:57:22.110">studios due to our microsoft into the services all of them run in</p>
      <p begin="00:57:22.110" end="00:57:26.670">our powered by data factory today so we're free pretty confident about kind of how battle hardened</p>
      <p begin="00:57:26.670" end="00:57:31.650">it's become inside the company now that we've started to bring it outside?</p>
      <p begin="00:57:31.650" end="00:57:36.380">With that I want to thank everybody for your time I really appreciate it I appreciate</p>
      <p begin="00:57:36.380" end="00:57:37.580">...talk to-you about data</p>
      <p begin="00:57:37.580" end="00:57:42.540">...be available at the booth for the next couple of hours after the session but I think we have with a couple of</p>
      <p begin="00:57:42.540" end="00:57:47.470">minutes so I'm happy to take any questions that people have it'll stick around for a few minutes after that thank you very much</p>
      <p begin="00:57:47.470" end="00:57:48.270">...it thanks.</p>

    </div>
  </body>
</tt>